# Meetstream Agent Operations Guide

This README expands on the base setup instructions and focuses on four day‑to‑day workflows:

1. Adding and managing MCP (Model Context Protocol) servers
2. Running the realtime bridge locally
3. Updating the agent’s tools, instructions, or topology
4. Swapping the realtime model provider (OpenAI ⇄ Gemini ⇄ Anthropic)

All paths below are relative to `meetstream-agent/`.

---

## 1. Stack Overview

- `app/agent.py` – defines the primary `RealtimeAgent`, local function tools (`current_time`, `weather_now`), and MCP wiring via `build_mcp_servers*`.
- `app/server.py` – FastAPI bridge that handles Meetstream audio/control sockets, instantiates a `RealtimeRunner`, and funnels audio/text to the agent.
- `app/static/` – Optional browser UI for debugging sessions via WebSocket.
- `pyproject.toml` + `uv.lock` – dependency definition, pinned via **uv**.

```
Meetstream (audio/text) → FastAPI bridge (`server.py`) → `RealtimeRunner`
                   ↑                                     ↓
                MCP outputs ← `agent.py` tools & MCP servers
```

---

## 2. Prerequisites

- Python 3.12 (managed automatically by `uv python install`)
- [uv](https://github.com/astral-sh/uv) CLI
- `npx` (comes with Node.js) for stdio-based MCP transports such as `mcp-remote`
- Provider API keys:
  - `OPENAI_API_KEY` for the default realtime stack
  - `GOOGLE_API_KEY` / `GEMINI_API_KEY` when targeting Gemini Live
  - `ANTHROPIC_API_KEY` when targeting Anthropic Realtime
- Optional MCP environment variables used by `build_mcp_servers_default()`:
  - `FRAMER_MCP_SSE_URL`
  - `N8N_MCP_SSE_URL` / `N8N_MCP_REMOTE_URL`
  - `N8N_MCP_AUTH` (or fallback `AUTH_TOKEN`)
  - `MCP_CONFIG` (path to a JSON config – defaults to `mcp.config.json`)

Keep any secrets in `.env` (ignored by git) and load them via `direnv`, `dotenv`, or your process manager.

---

## 3. Running the Bridge Locally

```bash
cd /Users/njawahar/Documents/Documents\ -\ Nav’s\ MacBook\ Air/Meetstream/meetstream-agents/meetstream-agent
uv python install            # once per machine, ensures the pinned interpreter
uv sync                      # installs dependencies into .venv

# Export env vars (API keys, MCP endpoints, etc.)
export OPENAI_API_KEY=sk-...
export FRAMER_MCP_SSE_URL=https://...

# Run FastAPI + WebSocket bridge
uv run uvicorn app.server:app --host 0.0.0.0 --port 8000 --reload
```

Verifications:
- `http://localhost:8000/` serves the static UI in `app/static/index.html`.
- `ws://localhost:8000/bridge` accepts Meetstream control traffic after sending `{"type":"ready","bot_id":"demo"}`.
- Logs such as `MCP servers to connect: ['framer', 'n8n', 'canva']` confirm pre-connection succeeded.

### Hot reload & development tips
- Use `uv run ipython` for quick REPL access with project dependencies.
- `uv run python -m http.server` can serve artifacts generated by MCP tools if needed.
- When editing `app/server.py`, rely on `uvicorn --reload` for auto-restart.

---

## 4. Adding New MCP Servers

There are two supported paths: declarative JSON configs or imperative Python wiring.

### 4.1 JSON-driven (preferred for deployments)

1. Create `mcp.config.json` next to `server.py`:

```json
{
  "mcpServers": {
    "playwright": {
      "type": "stdio",
      "command": "npx",
      "args": ["-y", "@playwright/mcp@latest", "--browser", "chromium"],
      "env": {
        "PW_USER_DATA_DIR": "$HOME/.cache/ms-playwright"
      },
      "timeout": 90
    },
    "internal-search": {
      "type": "streamable_http",
      "url": "https://search.internal/v1/mcp",
      "headers": {
        "Authorization": "Bearer $SEARCH_TOKEN"
      }
    },
    "design": {
      "type": "sse",
      "url": "https://design.example.com/mcp"
    }
  }
}
```

2. Point the agent at the file (optional if you keep the name `mcp.config.json`):

```bash
export MCP_CONFIG=/path/to/mcp.config.json
```

3. Restart the server. `build_mcp_servers_from_config()` (see `app/agent.py`) will:
   - Expand `$VARS` in commands, args, and headers
   - Instantiate `MCPServerStdio`, `MCPServerSse`, or `MCPServerStreamableHttp`
   - Cache tool manifests for faster startups

### 4.2 Code-driven/default wiring

If no config file is found, `build_mcp_servers_default()` bootstraps Framer (SSE), n8n (via `mcp-remote`), and Canva (stdio). Extend this list if you want the defaults baked into the repo:

```python
# app/agent.py
def build_mcp_servers_default() -> List[object]:
    servers: List[object] = []
    servers.append(my_custom_stdio(...))
    return servers
```

Recommended pattern:
- Keep each MCP block closed-over its own env vars.
- Use `MCPServerStdioParams` for anything launched via `npx` or a local binary.
- Leave `cache_tools_list=True` unless the MCP dynamically mutates its tools per session.

### 4.3 Pre-connecting MCPs

Both `app/agent.py` (`mcp_connect_once_if_needed`) and `app/server.py` (`_preconnect_mcp`) ensure every MCP is online before Meetstream traffic flows. If you add long-lived MCPs, call `await mcp_connect_once_if_needed()` during server startup to fail fast on bad credentials.

---

## 5. Modifying the Agent

### 5.1 Update instructions & voice
- Edit `AGENT_INSTRUCTIONS` in `app/agent.py` to steer persona or guardrails.
- Pass `voice="verse"` (or another OpenAI voice) to `RealtimeAgent(...)` if you want a different default.

### 5.2 Add local tools

Use `@function_tool` from `agents`:

```python
from agents import function_tool

@function_tool(
    name_override="search_tasks",
    description_override="Lookup Jira issues by ID."
)
async def search_tasks(ticket: str) -> str:
    ...

assistant_agent = RealtimeAgent(
    ...,
    tools=[current_time, weather_now, search_tasks],
)
```

Notes:
- Tool functions can be sync or async.
- Return plain text or JSON; the Realtime agent relays the string output to Meetstream.

### 5.3 Multi-agent or handoffs

`RealtimeAgent` supports sub-agents via the `handoffs` argument. Example:

```python
qa_agent = assistant_agent.clone(
    name="QA Specialist",
    instructions="Answer only testing questions."
)

assistant_agent = assistant_agent.clone(
    handoffs=[qa_agent]
)
```

Call `assistant_agent.clone(...)` to keep tool lists consistent while tweaking persona or guardrails.

### 5.4 MCP-aware prompts

Document new MCP tools inside `AGENT_INSTRUCTIONS` so the LLM understands when to call them (e.g., “Use `internal-search.*` tools to query Confluence.”). This mirrors the existing guidance for Canva/n8n.

---

## 6. Switching Model Providers

Out of the box, `RealtimeRunner` instantiates `OpenAIRealtimeWebSocketModel()` (see `agents/realtime/openai_realtime.py`). To target Gemini or Anthropic you provide an alternate `RealtimeModel` implementation and pass it into the runner.

### 6.1 General steps

1. Create a provider adapter that subclasses `agents.realtime.model.RealtimeModel` or wraps the default one.
2. Handle authentication, WebSocket URL negotiation, and translation between provider events and the toolkit’s `RealtimeModelEvent`s.
3. Update `BridgeManager.ensure_session()` to inject the model:

```python
from app.providers.gemini import GeminiRealtimeModel

...
model = GeminiRealtimeModel(
    api_key=os.getenv("GEMINI_API_KEY"),
    model="gemini-1.5-pro-exp",
    url="wss://generativelanguage.googleapis.com/v1beta/realtime:connect"
)
runner = RealtimeRunner(agent, model=model)
```

4. Restart the server and confirm audio/text flows end-to-end.

### 6.2 Gemini Live

- Transport: bidirectional WebSocket (`wss://generativelanguage.googleapis.com/v1beta/realtime:connect?key=...`).
- Authentication: query param `key=YOUR_KEY` or `Authorization: Bearer`.
- Audio shape: PCM16 16‑bit, 16kHz. Our bridge expects 24kHz; update `_resample_pcm16` targets or resample near the provider adapter.
- Implementation tips:
  - Mirror `agents/realtime/openai_realtime.py` for framing logic (tool calls become JSON events).
  - Gemini Live currently uses `device_input` / `server_content` message types – map them into `RealtimeModelSendUserInput` and `RealtimeModelAudioEvent`.
  - Ensure the adapter emits `RealtimeModelTranscriptDeltaEvent` for text tokens because `_pump_openai_events` buffers against `response.output_text.delta`.

### 6.3 Anthropic Realtime

- Transport: `wss://api.anthropic.com/v1/messages` with headers `x-api-key` + `anthropic-version: 2023-06-01`.
- Audio: Opus or PCM depending on tier; convert to PCM16 before forwarding to Meetstream.
- Tooling:
  - Anthropic exposes “input_text” and “input_audio” messages; wrap them inside `RealtimeModelSendUserInput`.
  - Tool calls arrive as `tool_call` payloads. Translate them to `RealtimeModelToolCallEvent` so the rest of the pipeline (MCP + `function_tool`s) stay unchanged.
- Latency guardrails: update `_resample_pcm16` rates if Anthropic uses 32kHz output.

### 6.4 Environment management

Create provider-specific `.env` entries:

```env
# .env
OPENAI_API_KEY=...
GEMINI_API_KEY=...
ANTHROPIC_API_KEY=...
REALTIME_PROVIDER=openai   # or gemini, anthropic
```

In `BridgeManager.ensure_session` you can branch on `REALTIME_PROVIDER` to choose the adapter:

```python
provider = os.getenv("REALTIME_PROVIDER", "openai")
if provider == "gemini":
    model = GeminiRealtimeModel(...)
elif provider == "anthropic":
    model = AnthropicRealtimeModel(...)
else:
    model = OpenAIRealtimeWebSocketModel()
runner = RealtimeRunner(agent, model=model)
```

---

## 7. Testing & Validation

- **Connection smoke test:** run `uv run python - <<'PY'` script that imports `agent.mcp_connect_all()` to ensure MCP endpoints are reachable before deploying.
- **Audio loopback:** send a short PCM clip through `/bridge/audio` using `websocat` to confirm resampling logic.
- **Tool health:** call `await agent.tools[i]()` inside an `ipython` session or trigger them via Meetstream UI to validate descriptions and outputs.
- **Provider swap dry run:** instantiate `RealtimeRunner(agent, model=YourModel())`, call `asyncio.run(runner.run().__aenter__())`, and send a single text turn to verify authentication without spinning up the FastAPI stack.

Document any team-specific MCP credentials or provider quirks adjacent to this README to keep onboarding simple.

---

## 8. Quick Reference

- Run server: `uv run uvicorn app.server:app --reload`
- Connect Meetstream control socket: send `{"type":"ready","bot_id":"demo"}` over `/bridge`
- Config-driven MCPs: `mcp.config.json` + `MCP_CONFIG` env
- Agent tweaks: edit `app/agent.py` (`AGENT_INSTRUCTIONS`, `tools`, `handoffs`)
- Provider swap: set `REALTIME_PROVIDER` + supply adapter implementing `agents.realtime.model.RealtimeModel`

Happy hacking! Keep this file updated whenever you add new MCP defaults or provider adapters so future contributors know the full workflow.


